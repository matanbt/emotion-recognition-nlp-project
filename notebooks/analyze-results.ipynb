{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emotions_list = ['admiration',\n",
    " 'amusement',\n",
    " 'anger',\n",
    " 'annoyance',\n",
    " 'approval',\n",
    " 'caring',\n",
    " 'confusion',\n",
    " 'curiosity',\n",
    " 'desire',\n",
    " 'disappointment',\n",
    " 'disapproval',\n",
    " 'disgust',\n",
    " 'embarrassment',\n",
    " 'excitement',\n",
    " 'fear',\n",
    " 'gratitude',\n",
    " 'grief',\n",
    " 'joy',\n",
    " 'love',\n",
    " 'nervousness',\n",
    " 'optimism',\n",
    " 'pride',\n",
    " 'realization',\n",
    " 'relief',\n",
    " 'remorse',\n",
    " 'sadness',\n",
    " 'surprise',\n",
    " 'neutral']\n",
    "\n",
    "ekman_mapping = {\n",
    "\"anger\": [\"anger\", \"annoyance\", \"disapproval\"],\n",
    "\"disgust\": [\"disgust\"],\n",
    "\"fear\": [\"fear\", \"nervousness\"],\n",
    "\"joy\": [\"joy\", \"amusement\", \"approval\", \"excitement\", \"gratitude\",  \"love\", \"optimism\", \"relief\", \"pride\", \"admiration\", \"desire\", \"caring\"],\n",
    "\"sadness\": [\"sadness\", \"disappointment\", \"embarrassment\", \"grief\",  \"remorse\"],\n",
    "\"surprise\": [\"surprise\", \"realization\", \"confusion\", \"curiosity\"],\n",
    " \"neutral\": [\"neutral\"]  # my addition\n",
    "}\n",
    "\n",
    "ekman_list = list(ekman_mapping.keys())\n",
    "\n",
    "sentiment_mapping = {\n",
    "\"positive\": [\"amusement\", \"excitement\", \"joy\", \"love\", \"desire\", \"optimism\", \"caring\", \"pride\", \"admiration\", \"gratitude\", \"relief\", \"approval\"],\n",
    "\"negative\": [\"fear\", \"nervousness\", \"remorse\", \"embarrassment\", \"disappointment\", \"sadness\", \"grief\", \"disgust\", \"anger\", \"annoyance\", \"disapproval\"],\n",
    "\"ambiguous\": [\"realization\", \"surprise\", \"curiosity\", \"confusion\"],\n",
    " \"neutral\": [\"neutral\"] # my addition TODO deal with\n",
    "}\n",
    "\n",
    "sent_list = list(sentiment_mapping.keys())\n",
    "\n",
    "\n",
    "vad_scaled_3 = [[0.93309693, 0.40324324, 0.74888093],\n",
    " [0.85298373, 0.8529148 , 0.85124654],\n",
    " [0.35      , 0.93645833, 0.66190476],\n",
    " [0.35      , 0.7029148 , 0.25428571],\n",
    " [0.65961538, 0.1496557 , 1.        ],\n",
    " [0.51681894, 0.17522124, 0.50763666],\n",
    " [0.40360139, 0.53629032, 0.11928571],\n",
    " [0.5825603 , 0.74439462, 0.42940171],\n",
    " [0.8       , 0.6559322 , 0.64216524],\n",
    " [0.21276596, 0.22282609, 0.23584906],\n",
    " [0.14673913, 0.34102564, 0.33333333],\n",
    " [0.        , 0.76689189, 0.1875    ],\n",
    " [0.26277372, 0.60860215, 0.04609665],\n",
    " [0.8       , 0.59917355, 0.75451264],\n",
    " [0.10326087, 0.86636771, 0.14785714],\n",
    " [0.74074074, 0.13511859, 0.5942813 ],\n",
    " [0.0923913 , 0.46370968, 0.44820513],\n",
    " [0.95807128, 0.83067293, 0.83733333],\n",
    " [1.        , 0.29069767, 0.70143241],\n",
    " [0.29927007, 1.        , 0.0639485 ],\n",
    " [0.88915009, 0.36742081, 0.88171745],\n",
    " [0.56307978, 0.44918919, 0.95464602],\n",
    " [0.48203991, 0.26453488, 0.93318966],\n",
    " [0.64659232, 0.04820513, 0.46925566],\n",
    " [0.1890411 , 0.55371901, 0.35370121],\n",
    " [0.        , 0.05286092, 0.        ],\n",
    " [0.70707071, 0.95402299, 0.55718702],\n",
    " [0.44739104, 0.        , 0.29714286]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# convert to better data-structures\n",
    "def get_key_of(mapping: dict[str, list[str]], val):\n",
    " \"\"\" Finds the key which `val` is an element in its list \"\"\"\n",
    " for key, lst in mapping.items():\n",
    "  if val in lst:\n",
    "   return key\n",
    " return None\n",
    "\n",
    "# idx --> group\n",
    "ekman_mapping_rev = []\n",
    "sentiment_mapping_rev = []\n",
    "\n",
    "for emotion in emotions_list:\n",
    " ekman_mapping_rev.append(get_key_of(ekman_mapping, emotion))\n",
    " sentiment_mapping_rev.append(get_key_of(sentiment_mapping, emotion))\n",
    "\n",
    "# ekman_mapping_rev"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# read evaluated data\n",
    "import numpy as np\n",
    "\n",
    "path_eval_labels= r\"C:\\Users\\MatanBT\\My Drive\\University\\Year 3\\Semester A\\Natural Language Processing\\NLP-Real-Project\\emotion-recognition-nlp-project\\paper-stuff\\cahced-models\\MAE_SCALED_checkpoint-20000\\eval_labels.csv\"\n",
    "\n",
    "path_eval_preds = r\"C:\\Users\\MatanBT\\My Drive\\University\\Year 3\\Semester A\\Natural Language Processing\\NLP-Real-Project\\emotion-recognition-nlp-project\\paper-stuff\\cahced-models\\MAE_SCALED_checkpoint-20000\\eval_preds.csv\"\n",
    "\n",
    "emo_lbl_idx_to_vad = vad_scaled_3\n",
    "\n",
    "eval_labels = np.loadtxt(path_eval_labels).astype(int)\n",
    "eval_preds = np.loadtxt(path_eval_preds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "Evaluating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "708b5705f55b45f481bd666de06f6feb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> accuracy: 0.5844327176781002\n"
     ]
    }
   ],
   "source": [
    "# 1NN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from datasets import tqdm\n",
    "\n",
    "metric = 'manhattan'  # manhattan # TODO try: 'euclidean'\n",
    "neigh = NearestNeighbors(n_neighbors=5, metric=metric)\n",
    "neigh.fit(emo_lbl_idx_to_vad)\n",
    "\n",
    "acc = np.zeros(len(eval_preds))\n",
    "top_3_acc = np.zeros(len(eval_preds)) # allows the true label to be in the TOP3 rather than in TOP1\n",
    "ekman_acc = np.zeros(len(eval_preds))\n",
    "sent_acc = np.zeros(len(eval_preds))\n",
    "\n",
    "eval_emotions = np.zeros((len(eval_preds), 2))\n",
    "eval_ekman = np.zeros((len(eval_preds), 2))  # col-label, col-result\n",
    "eval_sent = np.zeros((len(eval_preds), 2))   # col-label, col-result\n",
    "\n",
    "for i, vad_pred in tqdm(enumerate(eval_preds), desc=\"Evaluating\"):\n",
    " distances, labels = neigh.kneighbors(np.expand_dims(vad_pred, axis=0),\n",
    "                                      return_distance=True)\n",
    " # distances = 1 - (distances / 2 ** 0.5)  # scaler to probability\n",
    "\n",
    " eval_emotions[i] = [eval_labels[i], labels[0, 0]]\n",
    " acc[i] = (eval_labels[i] == labels[0, 0])\n",
    "\n",
    " top_3_acc[i] = (eval_labels[i] in labels[0, 0:3])\n",
    "\n",
    " eval_ekman[i] = [ekman_list.index(ekman_mapping_rev[eval_labels[i]]),\n",
    "                  ekman_list.index(ekman_mapping_rev[labels[0, 0]])]\n",
    " ekman_acc[i] = (eval_ekman[i][0] == eval_ekman[i][1])\n",
    "\n",
    " eval_sent[i] = [sent_list.index(sentiment_mapping_rev[eval_labels[i]]),\n",
    "              sent_list.index(sentiment_mapping_rev[labels[0, 0]])]\n",
    " sent_acc[i] = (eval_sent[i][0] == eval_sent[i][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Emotions Scores ****\n",
      ">> accuracy: 0.5844327176781002\n",
      ">> accuracy (top-3): 0.6358839050131926\n",
      ">> precision, recall, macro-f1: (0.4723648609384939, 0.4450570088465275, 0.4517017610183432, None)\n",
      "**** Ekman Scores ****\n",
      ">> accuracy: 0.6715039577836411\n",
      ">> precision, recall, macro-f1: (0.603631220744588, 0.5715711896630478, 0.5860706762329626, None)\n",
      "**** Sentiment Scores ****\n",
      ">> accuracy: 0.6921723834652594\n",
      ">> precision, recall, macro-f1: (0.6571358747243233, 0.648803506220825, 0.6527193488738827, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\matanbt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Calc scores:\n",
    "print(f\"**** Emotions Scores [Overall] ****\")\n",
    "print(f\">> accuracy: {acc.mean()}\")\n",
    "print(f\">> accuracy (top-3): {top_3_acc.mean()}\")\n",
    "print(f\">> precision, recall, macro-f1: {precision_recall_fscore_support(eval_emotions[:, 0], eval_emotions[:, 1], average='macro')}\")\n",
    "\n",
    "print(f\"**** Ekman Scores [Overall]  ****\")\n",
    "print(f\">> accuracy: {ekman_acc.mean()}\")\n",
    "print(f\">> precision, recall, macro-f1: {precision_recall_fscore_support(eval_ekman[:, 0], eval_ekman[:, 1], average='macro')}\")\n",
    "\n",
    "print(f\"**** Sentiment Scores [Overall]  ****\")\n",
    "print(f\">> accuracy: {sent_acc.mean()}\")\n",
    "print(f\">> precision, recall, macro-f1: {precision_recall_fscore_support(eval_sent[:, 0], eval_sent[:, 1], average='macro')}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Emotion `admiration`\n",
      "   >> accuracy: 0.9575637642919965\n",
      "   >> precision, recall, macro-f1: (0.6811989100817438, 0.7668711656441718, 0.7215007215007213, None)\n",
      ">>> Emotion `amusement`\n",
      "   >> accuracy: 0.9773526824978013\n",
      "   >> precision, recall, macro-f1: (0.7091633466135459, 0.8557692307692307, 0.775599128540305, None)\n",
      ">>> Emotion `anger`\n",
      "   >> accuracy: 0.9797713280562885\n",
      "   >> precision, recall, macro-f1: (0.6, 0.46788990825688076, 0.5257731958762887, None)\n",
      ">>> Emotion `annoyance`\n",
      "   >> accuracy: 0.9397537379067722\n",
      "   >> precision, recall, macro-f1: (0.2544642857142857, 0.3475609756097561, 0.2938144329896907, None)\n",
      ">>> Emotion `approval`\n",
      "   >> accuracy: 0.940193491644679\n",
      "   >> precision, recall, macro-f1: (0.4588235294117647, 0.3023255813953488, 0.36448598130841114, None)\n",
      ">>> Emotion `caring`\n",
      "   >> accuracy: 0.9659190853122251\n",
      "   >> precision, recall, macro-f1: (0.2748091603053435, 0.375, 0.31718061674008813, None)\n",
      ">>> Emotion `confusion`\n",
      "   >> accuracy: 0.969217238346526\n",
      "   >> precision, recall, macro-f1: (0.33035714285714285, 0.3627450980392157, 0.34579439252336447, None)\n",
      ">>> Emotion `curiosity`\n",
      "   >> accuracy: 0.9599824098504838\n",
      "   >> precision, recall, macro-f1: (0.4470588235294118, 0.4634146341463415, 0.4550898203592814, None)\n",
      ">>> Emotion `desire`\n",
      "   >> accuracy: 0.9876868953386104\n",
      "   >> precision, recall, macro-f1: (0.46296296296296297, 0.4807692307692308, 0.4716981132075472, None)\n",
      ">>> Emotion `disappointment`\n",
      "   >> accuracy: 0.9626209322779243\n",
      "   >> precision, recall, macro-f1: (0.1623931623931624, 0.2087912087912088, 0.1826923076923077, None)\n",
      ">>> Emotion `disapproval`\n",
      "   >> accuracy: 0.9503078276165348\n",
      "   >> precision, recall, macro-f1: (0.4533333333333333, 0.32075471698113206, 0.37569060773480656, None)\n",
      ">>> Emotion `disgust`\n",
      "   >> accuracy: 0.9859278803869833\n",
      "   >> precision, recall, macro-f1: (0.46938775510204084, 0.3770491803278688, 0.41818181818181815, None)\n",
      ">>> Emotion `embarrassment`\n",
      "   >> accuracy: 0.997141600703606\n",
      "   >> precision, recall, macro-f1: (0.7333333333333333, 0.55, 0.6285714285714286, None)\n",
      ">>> Emotion `excitement`\n",
      "   >> accuracy: 0.9819700967458224\n",
      "   >> precision, recall, macro-f1: (0.21153846153846154, 0.21153846153846154, 0.21153846153846154, None)\n",
      ">>> Emotion `fear`\n",
      "   >> accuracy: 0.9940633245382586\n",
      "   >> precision, recall, macro-f1: (0.8297872340425532, 0.6724137931034483, 0.7428571428571429, None)\n",
      ">>> Emotion `gratitude`\n",
      "   >> accuracy: 0.9861477572559367\n",
      "   >> precision, recall, macro-f1: (0.8639705882352942, 0.9003831417624522, 0.8818011257035648, None)\n",
      ">>> Emotion `grief`\n",
      "   >> accuracy: 0.9986807387862797\n",
      "   >> precision, recall, macro-f1: (0.0, 0.0, 0.0, None)\n",
      ">>> Emotion `joy`\n",
      "   >> accuracy: 0.9830694810905892\n",
      "   >> precision, recall, macro-f1: (0.7543859649122807, 0.4056603773584906, 0.5276073619631902, None)\n",
      ">>> Emotion `love`\n",
      "   >> accuracy: 0.9813104661389622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\matanbt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   >> precision, recall, macro-f1: (0.7, 0.8901734104046243, 0.7837150127226463, None)\n",
      ">>> Emotion `nervousness`\n",
      "   >> accuracy: 0.9975813544415127\n",
      "   >> precision, recall, macro-f1: (0.3333333333333333, 0.375, 0.35294117647058826, None)\n",
      ">>> Emotion `optimism`\n",
      "   >> accuracy: 0.9795514511873351\n",
      "   >> precision, recall, macro-f1: (0.6382978723404256, 0.5042016806722689, 0.5633802816901409, None)\n",
      ">>> Emotion `pride`\n",
      "   >> accuracy: 0.9978012313104662\n",
      "   >> precision, recall, macro-f1: (0.0, 0.0, 0.0, None)\n",
      ">>> Emotion `realization`\n",
      "   >> accuracy: 0.9819700967458224\n",
      "   >> precision, recall, macro-f1: (0.4, 0.21621621621621623, 0.2807017543859649, None)\n",
      ">>> Emotion `relief`\n",
      "   >> accuracy: 0.9958223394898856\n",
      "   >> precision, recall, macro-f1: (0.0, 0.0, 0.0, None)\n",
      ">>> Emotion `remorse`\n",
      "   >> accuracy: 0.9940633245382586\n",
      "   >> precision, recall, macro-f1: (0.6511627906976745, 0.7, 0.674698795180723, None)\n",
      ">>> Emotion `sadness`\n",
      "   >> accuracy: 0.9843887423043096\n",
      "   >> precision, recall, macro-f1: (0.5915492957746479, 0.5, 0.5419354838709677, None)\n",
      ">>> Emotion `surprise`\n",
      "   >> accuracy: 0.981750219876869\n",
      "   >> precision, recall, macro-f1: (0.5666666666666667, 0.5368421052631579, 0.5513513513513513, None)\n",
      ">>> Emotion `neutral`\n",
      "   >> accuracy: 0.7572559366754618\n",
      "   >> precision, recall, macro-f1: (0.6482381530984204, 0.6702261306532663, 0.6590487955528104, None)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate emotions per emotion\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for idx, emotion in enumerate(emotions_list):\n",
    " eval_emotion_only = (eval_emotions == idx).astype(int)\n",
    " print(f\">>> Emotion `{emotion}`\")\n",
    " print(f\"   >> accuracy: {accuracy_score(eval_emotion_only[:, 0], eval_emotion_only[:, 1])}\")\n",
    " print(f\"   >> precision, recall, F1: {precision_recall_fscore_support(eval_emotion_only[:, 0], eval_emotion_only[:, 1], average='binary')}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Category `anger`\n",
      "   >> accuracy: 0.8975373790677221\n",
      "   >> precision, recall, F1: (0.5206971677559913, 0.4927835051546392, 0.5063559322033898, None)\n",
      ">>> Category `disgust`\n",
      "   >> accuracy: 0.9859278803869833\n",
      "   >> precision, recall, F1: (0.46938775510204084, 0.3770491803278688, 0.41818181818181815, None)\n",
      ">>> Category `fear`\n",
      "   >> accuracy: 0.9916446789797714\n",
      "   >> precision, recall, F1: (0.75, 0.6363636363636364, 0.6885245901639345, None)\n",
      ">>> Category `joy`\n",
      "   >> accuracy: 0.8518029903254177\n",
      "   >> precision, recall, F1: (0.7958333333333333, 0.8015587529976019, 0.7986857825567503, None)\n",
      ">>> Category `sadness`\n",
      "   >> accuracy: 0.947009674582234\n",
      "   >> precision, recall, F1: (0.5, 0.5103734439834025, 0.5051334702258726, None)\n",
      ">>> Category `surprise`\n",
      "   >> accuracy: 0.9118293755496921\n",
      "   >> precision, recall, F1: (0.5412621359223301, 0.5126436781609195, 0.5265643447461629, None)\n",
      ">>> Category `neutral`\n",
      "   >> accuracy: 0.7572559366754618\n",
      "   >> precision, recall, F1: (0.6482381530984204, 0.6702261306532663, 0.6590487955528104, None)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Ekman per category\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for idx, category in enumerate(ekman_list):\n",
    " eval_emotion_only = (eval_ekman == idx).astype(int)\n",
    " print(f\">>> Category `{category}`\")\n",
    " print(f\"   >> accuracy: {accuracy_score(eval_emotion_only[:, 0], eval_emotion_only[:, 1])}\")\n",
    " print(f\"   >> precision, recall, F1: {precision_recall_fscore_support(eval_emotion_only[:, 0], eval_emotion_only[:, 1], average='binary')}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Sentiment: `positive`\n",
      "   >> accuracy: 0.8518029903254177\n",
      "   >> precision, recall, F1: (0.7958333333333333, 0.8015587529976019, 0.7986857825567503, None)\n",
      ">>> Sentiment: `negative`\n",
      "   >> accuracy: 0.8634564643799473\n",
      "   >> precision, recall, F1: (0.6432098765432098, 0.6107854630715123, 0.6265784726398075, None)\n",
      ">>> Sentiment: `ambiguous`\n",
      "   >> accuracy: 0.9118293755496921\n",
      "   >> precision, recall, F1: (0.5412621359223301, 0.5126436781609195, 0.5265643447461629, None)\n",
      ">>> Sentiment: `neutral`\n",
      "   >> accuracy: 0.7572559366754618\n",
      "   >> precision, recall, F1: (0.6482381530984204, 0.6702261306532663, 0.6590487955528104, None)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Sentiment per sentiment\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for idx, sent in enumerate(sent_list):\n",
    " eval_emotion_only = (eval_sent == idx).astype(int)\n",
    " print(f\">>> Sentiment: `{sent}`\")\n",
    " print(f\"   >> accuracy: {accuracy_score(eval_emotion_only[:, 0], eval_emotion_only[:, 1])}\")\n",
    " print(f\"   >> precision, recall, F1: {precision_recall_fscore_support(eval_emotion_only[:, 0], eval_emotion_only[:, 1], average='binary')}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}